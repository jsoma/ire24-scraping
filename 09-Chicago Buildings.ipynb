{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d53484e-96f5-4247-8143-0c2e2a97898d",
   "metadata": {},
   "source": [
    "Traditionally Python programmers use [BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/) to scrape content from the interent. Instead of being *traditional*, we're going to use [Playwright](https://playwright.dev/python/), a **browser automation tool**! This means you actually control the browser! Filling out forms, clicking buttons, downloading documents... it's magic!!!✨✨✨\n",
    "\n",
    "# Chicago Building Records\n",
    "\n",
    "- Clicking\n",
    "- Filling out forms with `type` instead of `fill`\n",
    "- Extracting a single table\n",
    "- Looping through addresses\n",
    "- CSS selectors?\n",
    "- Clicking links\n",
    "- Dataframe manipulation\n",
    "- Combining dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e6a6d7-d5af-47bf-b29a-27b291399ae4",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "We need to install a few tools first! Remove the `#` and run the cell to install the Python packages and browsers that we'll need for our scraping adventure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7216c80-6474-48f8-9f27-768ad8cc88cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --quiet lxml html5lib beautifulsoup4 pandas\n",
    "# %pip install --quiet playwright\n",
    "# !playwright install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63433e5-8013-47b8-a6c6-92419916708d",
   "metadata": {},
   "source": [
    "## Opening up the browser and visiting our destination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e2e5c0-9641-47c0-a71a-122fb40589f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "\n",
    "# \"Hey, open up a browser\"\n",
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless=False)\n",
    "context = await browser.new_context()\n",
    "\n",
    "# Create a new browser window\n",
    "page = await context.new_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2396e4-9eb2-44c3-8961-3266188eb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "await page.goto(\"https://webapps1.chicago.gov/buildingrecords/home\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e30a45c-26fa-4707-86e9-fd5d340afec3",
   "metadata": {},
   "source": [
    "## Clicking a button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4af410-be35-4e4b-b907-faf13935dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "await page.locator(\"#rbnAgreement1\").click()\n",
    "await page.get_by_text(\"Submit\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8268b-3354-46ea-bc47-0d5574d1d7fd",
   "metadata": {},
   "source": [
    "## Filling in a field that *demands* keyboard input\n",
    "\n",
    "You usually use `.fill` to write in a text box. But some forms want to know someone typed in it! In this case, you'll use `.type` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc1c555-1d1b-499f-98f5-9d8d2316b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# await page.locator(\"input\").fill(\"400 e 41st st\")\n",
    "# await page.get_by_label(\"Building Address\").fill(\"400 e 41st st\")\n",
    "await page.get_by_label(\"Building Address\").type(\"400 e 41st st\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3446152a-3523-4d5f-bbcb-df120d26d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "await page.get_by_text(\"Submit\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c004864-e6a2-4d89-bba1-1cd3552bc620",
   "metadata": {},
   "source": [
    "## Grab the data from the page\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) is the Python equivalent to Excel, and it's great at dealing with tabular data! Often the data on a web page that looks like a spreadsheet can be read with `pd.read_html`.\n",
    "\n",
    "In this case, there *isn't one*. You need to use BeautifulSoup to scrape the page manually! *But* you first needed to use Playwright to open hte page, execute the search, and scrollllll to fill up the page first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be6a9b-c861-4e5a-b95e-3de2548c225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "html = await page.content()\n",
    "tables = pd.read_html(StringIO(html))\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10937f40-5244-4bea-8853-88cd1ece2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tables[2]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebbc24e-5ee3-40c0-8e2e-68e72d3d58d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcc5ba6-75e1-4c1a-bcbd-547925d038e9",
   "metadata": {},
   "source": [
    "## Getting details of each of the inspections\n",
    "\n",
    "How many links are on the page? I found `\"#resultstable_inspections a\"` by knowing how CSS selectors work. It means \"links inside of an element with an id of `resultstable_inspections`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3bd3f-5d46-4fcb-8e57-60c950e3579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = page.locator(\"#resultstable_inspections a\")\n",
    "count = await links.count()\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b4d5b-1d0b-4fd5-8627-2c2935b33efb",
   "metadata": {},
   "source": [
    "### Clicking a single link for details\n",
    "\n",
    "When we click the link it opens up a new page. Below we click one of the links and wait until the \"Print\" text shows up on the page. We can talk about the new page with `new_page`, while `page` is still the original page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d6a56a-00ee-4834-98fc-9410c30d4aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with context.expect_page() as new_page_info:\n",
    "    await links.nth(1).click()\n",
    "\n",
    "new_page = await new_page_info.value\n",
    "await new_page.get_by_text(\"Print\").wait_for()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b1a324-de59-4bf6-b1d7-73c2bf9d583c",
   "metadata": {},
   "source": [
    "Now we'll pull the content from the new page just like we normally do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d8f69-5028-4a02-9910-1ed2988f899f",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = await new_page.content()\n",
    "tables = pd.read_html(StringIO(html))\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf80435-04f6-44f3-a09d-fe7c3d8f8a80",
   "metadata": {},
   "source": [
    "It's kind of a weird table, so we need to clean it up a bit. I know I (probably) promised that all of this would be 100% cut-and-paste reuseable but SADLY this time it is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d11a03-fe55-4217-8cac-74dbfe3e52ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tables[0]\n",
    "df.columns = df.columns.droplevel()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494e43c0-59e8-4076-9999-efe74bf7c1ca",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "Let's experiment with looking through the different links, and then make it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca4f0a7-2947-43a6-bb24-0626f2a1fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = page.locator(\"#resultstable_inspections a\")\n",
    "count = await links.count()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0376c659-3b8c-40ed-98e5-88f8e8f5dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    link = links.nth(i)\n",
    "    inspection_num = await links.nth(i).inner_text()\n",
    "    print(\"Inspection number\", inspection_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8857f9a-2e56-4e4f-af9e-722f659d1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    link = links.nth(i)\n",
    "    inspection_num = await links.nth(i).inner_text()\n",
    "    print(\"Inspection number\", inspection_num)\n",
    "\n",
    "    async with context.expect_page() as new_page_info:\n",
    "        await link.click()\n",
    "\n",
    "    new_page = await new_page_info.value\n",
    "    await new_page.get_by_text(\"Print\").wait_for()\n",
    "\n",
    "    await new_page.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b3f161-fdd3-491c-bd39-af7e5def9a30",
   "metadata": {},
   "source": [
    "Okay let's go!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0dcc95-b510-40ce-b1bd-54467ded2340",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame()\n",
    "\n",
    "# for i in range(count):\n",
    "for i in range(5):\n",
    "    # Get the link and the link details\n",
    "    link = links.nth(i)\n",
    "    inspection_num = await links.nth(i).inner_text()\n",
    "\n",
    "    # Open the page\n",
    "    async with context.expect_page() as new_page_info:\n",
    "        await link.click()\n",
    "\n",
    "    # Access the page\n",
    "    new_page = await new_page_info.value\n",
    "    await new_page.get_by_text(\"Print\").wait_for()\n",
    "\n",
    "    # Grab the table\n",
    "    try:\n",
    "        print(\"Saving violations for\", inspection_num)\n",
    "        html = await new_page.content()\n",
    "        tables = pd.read_html(StringIO(html), header=None)\n",
    "        df = tables[0]\n",
    "        df.columns = df.columns.droplevel()\n",
    "        df['inspection_num'] = inspection_num\n",
    "        all_data = pd.concat([all_data, df], ignore_index = True)\n",
    "    except:\n",
    "        print(\"No violations for\", inspection_num)\n",
    "        \n",
    "    # Close the page\n",
    "    await new_page.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06a02d4-5707-4cb5-afbb-fd1f0168c22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d1dfaa-d0d7-427e-b67a-b864ed4c2807",
   "metadata": {},
   "source": [
    "## Saving the results\n",
    "\n",
    "Now we'll save it to a CSV file! Easy peasy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1295aee-6b4a-41b8-8208-f07edf6a2aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc182f-1695-4fbe-bdba-5dca0754a7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
