{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a43a97a-85aa-4251-a05d-5ec2cc91fe44",
   "metadata": {},
   "source": [
    "In this example we are going to scrape [locksmiths](https://www.dllr.state.md.us/cgi-bin/ElectronicLicensing/OP_Search/OP_search.cgi?calling_app=LOCKSMITH::LOCKSMITH_personal_location) from Maryland's [licensing queries](https://www.dllr.state.md.us/pq/) site.\n",
    "\n",
    "\n",
    "Traditionally Python programmers use [BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/) to scrape content from the interent. Instead of being *traditional*, we're going to use [Playwright](https://playwright.dev/python/), a **browser automation tool**! This means you actually control the browser! Filling out forms, clicking buttons, downloading documents... it's magic!!!✨✨✨\n",
    "\n",
    "# Maryland locksmiths\n",
    "\n",
    "- Inspecting the page\n",
    "- Filling in a text box\n",
    "- Working through a list of inputs (zip codes, in this case)\n",
    "- Combining dataframes\n",
    "- Back button"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee675aba-820b-4af6-87c9-8e678ded7df9",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "We need to install a few tools first! Remove the `#` and run the cell to install the Python packages and browsers that we'll need for our scraping adventure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7216c80-6474-48f8-9f27-768ad8cc88cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --quiet lxml html5lib beautifulsoup4 pandas\n",
    "# %pip install --quiet playwright\n",
    "# !playwright install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5144ddcd-7ec1-44db-9d4a-a605d3013a6d",
   "metadata": {},
   "source": [
    "## Opening up the browser and visiting our destination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e2e5c0-9641-47c0-a71a-122fb40589f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "\n",
    "# \"Hey, open up a browser\"\n",
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless=False)\n",
    "\n",
    "# Create a new browser window\n",
    "page = await browser.new_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2396e4-9eb2-44c3-8961-3266188eb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "await page.goto(\"https://www.dllr.state.md.us/cgi-bin/ElectronicLicensing/OP_Search/OP_search.cgi?calling_app=LOCKSMITH::LOCKSMITH_personal_location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c8e231-47ce-451f-a365-8789f512cc9c",
   "metadata": {},
   "source": [
    "## Filling in a text box\n",
    "\n",
    "You always start with `await page.locator(\"input\").fill(\"whatever you want\")`. You'll probably get an error because there are multiple inputs on the page, but Playwright doesn't know which one you want to use! Just read the error and figure out the right one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4af410-be35-4e4b-b907-faf13935dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20601 \n",
    "# 20602\n",
    "# 20603\n",
    "# 20606\n",
    "# 20607\n",
    "# 20608\n",
    "# 20609\n",
    "\n",
    "# await page.locator(\"input\").fill(\"20601\")\n",
    "await page.locator(\"[name='zip']\").fill(\"20601\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc1c555-1d1b-499f-98f5-9d8d2316b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# await page.get_by_text(\"Search\").click()\n",
    "await page.get_by_role(\"button\", name=\"Search\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb8d3d1-2eb1-4942-9403-5e99a89309e3",
   "metadata": {},
   "source": [
    "## Grab the tables from the page\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) is the Python equivalent to Excel, and it's great at dealing with tabular data! Often the data on a web page that looks like a spreadsheet can be read with `pd.read_html`.\n",
    "\n",
    "You use `await page.content()` to save the contents of the page, then feed it to `read_html` to find the tables. `len(tables)` checks the number of tables you have, then you manually poke around to see which one is the one you're interested in. `tables[0]` is the first one, `tables[1]` is the second one, and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be6a9b-c861-4e5a-b95e-3de2548c225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "html = await page.content()\n",
    "tables = pd.read_html(StringIO(html))\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c6e02-fa86-4075-b80b-f15e81ed4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebbc24e-5ee3-40c0-8e2e-68e72d3d58d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "await page.go_back()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeaefe1-cd74-4d86-a8a6-ef80c31f7665",
   "metadata": {},
   "source": [
    "## Fill out the ZIP code field again and again and again\n",
    "\n",
    "I found a list of zipcodes on the internet! I pasted them below, then used `.split()` to make them into something we could use in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78680b8c-2b86-448d-9318-7e0e12031fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcodes = \"\"\"20906\n",
    "21234\n",
    "20878\n",
    "21740\n",
    "20874\n",
    "21122\n",
    "21222\n",
    "21117\n",
    "20904\n",
    "20744\n",
    "21061\n",
    "21215\n",
    "20902\n",
    "20772\n",
    "21207\n",
    "20850\n",
    "21206\n",
    "20774\n",
    "20783\n",
    "21228\n",
    "20854\n",
    "20852\n",
    "21043\n",
    "21702\n",
    "21218\n",
    "21044\n",
    "21921\n",
    "20910\n",
    "21224\n",
    "21229\"\"\".split(\"\\n\")\n",
    "\n",
    "print(zipcodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68183a4d-0ad8-4b81-bc4d-b70fc67b37b0",
   "metadata": {},
   "source": [
    "Now we fill out the form for each and every zip code, one by one, pulling out the tables and saving them and adding them to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4102aa-4ff0-4212-9896-1db04cb0617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Go to the front page\n",
    "await page.goto(\"https://www.dllr.state.md.us/cgi-bin/ElectronicLicensing/OP_Search/OP_search.cgi?calling_app=LOCKSMITH::LOCKSMITH_personal_location\")\n",
    "\n",
    "# Search for each zipcode\n",
    "for zipcode in zipcodes:\n",
    "    print(\"Searching for\", zipcode)\n",
    "\n",
    "    # Fill out the form and search\n",
    "    await page.locator(\"[name='zip']\").fill(zipcode)\n",
    "    await page.get_by_role(\"button\", name=\"Search\").click()\n",
    "\n",
    "    # try:\n",
    "    # Get all of the tables on the page\n",
    "    html = await page.content()\n",
    "    try:\n",
    "        tables = pd.read_html(StringIO(html))\n",
    "    except:\n",
    "        tables = []\n",
    "\n",
    "    # Get the table (and edit if necessary)\n",
    "    if len(tables) > 0:\n",
    "        df = tables[0]\n",
    "        print(\"Found\", len(df))\n",
    "    \n",
    "        # Add the tables on this page to \n",
    "        all_data = pd.concat([all_data, df], ignore_index = True)\n",
    "    else:\n",
    "        print(\"Nothing found\")\n",
    "\n",
    "    # Go back and start again\n",
    "    await page.go_back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc499cd-4804-4ec4-9189-b2a14fdb4c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f610e3-9320-4726-9aed-6c6ef8d333c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9009845c-d3ba-4b27-98eb-bcbd97946f0c",
   "metadata": {},
   "source": [
    "## Saving the results\n",
    "\n",
    "Now we'll save it to a CSV file! Easy peasy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66248fd9-0e86-4fbe-954d-53c004c9237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv(\"output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3bd3f-5d46-4fcb-8e57-60c950e3579b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
